{"cells":[{"cell_type":"code","execution_count":null,"id":"d65643ee","metadata":{"id":"d65643ee"},"outputs":[],"source":["from selenium import webdriver\n","import time\n","import base64\n","import requests\n","from bs4 import BeautifulSoup\n","import csv\n","from csv import writer\n","import json\n","from selenium.webdriver.common.action_chains import ActionChains\n","from selenium.webdriver.common.by import By"]},{"cell_type":"code","execution_count":null,"id":"45b64b0a","metadata":{"id":"45b64b0a"},"outputs":[],"source":["browser = webdriver.Chrome()\n","browser.maximize_window()\n","final = \"next_page\"\n","a1 = \"it was amazing\"\n","a2 = \"really liked it\"\n","a3 = \"liked it\"\n","a4 = \"it was ok\"\n","a5 = \"did not like it\"\n","i=0\n","\n","with open(\"Books_ratings.csv\",\"a\", newline=\"\") as outfile:\n","    csv_writer = writer(outfile)\n","    csv_writer.writerow([\"Book_ID\",\"User_ID\",\"Ratings\",\"Timestamp\"])\n","    f = open('Goodreads_URL.txt')\n","    for line in f:\n","\n","        browser.get(line)\n","        time.sleep(1)\n","        \n","        try:\n","            browser.find_element(By.XPATH, \"/html/body/div[3]/div/div/div[1]/button/img\").click()\n","        except:\n","            pass\n","\n","        for i in range(0,10):\n","            try:\n","                browser.find_element(By.XPATH, \"/html/body/div[3]/div/div/div[1]/button/img\").click()\n","            except:\n","                pass \n","\n","            time.sleep(2)\n","\n","            a = browser.page_source\n","            resp=BeautifulSoup(a,\"html.parser\")\n","\n","            ir = resp.find(class_ = 'asyncPreviewButtonContainer')\n","            b_id = ir['data-book-id']    \n","    #         print(\"Book ID:\", b_id)\n","    \n","            rev = resp.find_all(class_ = 'friendReviews elementListBrown')     # Review Persons\n","            nan = len(rev)\n","            \n","            for r in rev:\n","                r1 = r.find('div')\n","                r2 = r1.find('div')        \n","                n = r2.find('a')\n","                timestamp = r2.find(class_ = 'reviewDate createdAt right')\n","                ts = timestamp.text\n","\n","                try:\n","                    rat = r2.find(class_ = 'left bodycol')\n","                    rat1 = rat.find(class_ = 'reviewHeader uitext stacked')\n","                    rat2 = rat1.find(class_ = 'staticStars notranslate')\n","                    u_rat = rat2['title']\n","\n","                    if (u_rat == a1):\n","                        ra = 5            \n","                    if (u_rat == a2):\n","                        ra = 4            \n","                    if (u_rat == a3):\n","                        ra = 3        \n","                    if (u_rat == a4):\n","                        ra = 2        \n","                    if (u_rat == a5):\n","                        ra = 1\n","                    id1 = n['href']\n","                    id2 = id1.replace(\"/user/show/\",\"\")\n","                    head, sep, tail = id2.partition('-')\n","                    \n","                except:\n","                    pass\n","\n","                csv_writer.writerow([b_id,head,ra,ts])\n","                     \n","            try:\n","                element = browser.find_element(By.XPATH,\"/html/body/div[2]/div[3]/div[1]/div[2]/div[4]/div[3]/div[4]/div[2]/div/div[1]/div[4]/div[%d]\"%(nan))\n","                actions = ActionChains(browser)\n","                actions.move_to_element(element).perform()\n","                time.sleep(3)\n","            except:\n","                continue\n","            \n","            if(i==0):\n","                try:\n","                    element = browser.find_element(By.XPATH,\"/html/body/div[2]/div[3]/div[1]/div[2]/div[4]/div[3]/div[4]/div[2]/div/div[1]/div[5]/div/a[9]\")\n","                    actions = ActionChains(browser)\n","                    actions.move_to_element(element).perform()\n","                    time.sleep(1)\n","                    element.click()\n","                    \n","                except:\n","                    continue\n","\n","            else:\n","                try:    \n","                    element = browser.find_element(By.XPATH,\"/html/body/div[2]/div[3]/div[1]/div[2]/div[4]/div[3]/div[4]/div[2]/div/div[1]/div[5]/div/a[11]\")\n","                    actions = ActionChains(browser)\n","                    actions.move_to_element(element).perform()\n","                    time.sleep(1)\n","                    element.click()\n","                except:\n","                    pass"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"GoodReads_Scrap_Book_Reviews.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}
